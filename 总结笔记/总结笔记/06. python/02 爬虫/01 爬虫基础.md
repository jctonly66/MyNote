---
typora-copy-images-to: assets
---

## 一、爬虫基础

网络爬虫（又被称为网页蜘蛛，网络机器人）就是模拟客户端发送网络请求，接收请求响应，一种按照一定的规则，自动地抓取互联网信息的程序。

### 1. 爬虫的分类

1. 通用爬虫：通常指搜索引擎的爬虫；
2. 聚焦爬虫：针对特定网站的爬虫；

### 2. ROBOTS协议

Robots协议：网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。

### 3. url的形式

```
scheme://host[:port#]/path/.../[?query-string][#anchor]
```

- scheme：协议(例如：http、https、ftp)
- anchor：锚（跳转到网页的指定锚点位置）

### 4. HTTP常见请求头

- Host (主机和端口号)
- Connection (链接类型)：keep-alive，长连接与短连接
- Upgrade-Insecure-Requests (升级为HTTPS请求)
- User-Agent (浏览器名称)  ******
- Accept (传输文件类型)：浏览器或其他客户端可以接受的MIME文件类型，服务器可以根据它判断并返回适当的文件格式。
- Referer (页面跳转处)：表明产生请求的网页来自于哪个URL，用户是从该Referer页面访问到当前请求的页面。
- Accept-Encoding（文件编解码格式）
- Cookie （Cookie）******：Cookie是在浏览器中寄存的小型数据体，它可以记载和服务器相关的用户信息，也可以用来实现会话功能。
- x-requested-with :XMLHttpRequest  (是Ajax 异步请求)

### 5. 常用的网络库

requests

### 6. 使用代理

为什么爬虫需要使用代理？

1. 让服务器以为不是同一个客户端在请求
2. 防止我们的真实地址被泄露，防止被追究

### 7. cookie与session区别

1. cookie数据存放在客户的浏览器上，session数据放在服务器上。
2. cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗。
3. session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能。
4. 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。

使用cookie和session能够请求到登录之后的页面，但是一套cookie和session往往和一个用户对应。请求太快，请求次数太多，容易被服务器识别为爬虫，所以不需要cookie的时候尽量不去使用cookie，但是为了获取登录之后的页面，我们必须发送带有cookies的请求。

## 二、数据提取

一般，爬取到的数据会分类两大类：

1. 非结构化数据，比如HTML等，此类数据需要通过正则表达式、xpath等处理；
2. 结构化数据，比如json,xml等，此类数据需要转化为python数据类型处理。

### 1. XML数据提取

XPath使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。

![1564364467262](.\assets\1564364467262.png)

![1564364552289](.\assets\1564364552289.png)

![1564364608724](.\assets\1564364608724.png)

![1564364622456](.\assets\1564364622456.png)

#### 1.1 lxml库

使用方法：

```python
# 导入lxml 的 etree 库 
from lxml import etree
# 利用etree.HTML，将字符串转化为Element对象
html = etree.HTML(text) 
# Element对象具有xpath的方法
```

## 三、爬虫思路总结

1. 有一些验证码，会跟每个用户的信息绑定，此时，发送post请求时，会对比post请求中发的验证码和当前用户真正的存储在服务器端的验证码验证是否相同。

   解决办法：

   1. 实例化session
   2. 使用session请求登录页面，获取验证码的地址
   3. 使用session请求验证码，识别
   4. 使用session发送post请求

2. Selenium使用的注意点：

   1. selenium只能定位到元素，之后才能获取元素的值或者属性。
   2. 如果页面中含有iframe、frame，需要先调用switch_to的方法切换到frame中才能定位元素
   3. selenium请求第一页的时候会等待页面加载完了之后再获取数据，但是点击翻页后，会直接获取数据。